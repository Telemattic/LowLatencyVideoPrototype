#ifndef __STDC_CONSTANT_MACROS
#define __STDC_CONSTANT_MACROS
#endif

extern "C"
{
#include <libavcodec/avcodec.h>
#include <libswscale/swscale.h>
}
#include <stddef.h>
#include <stdint.h>
#include <stdio.h>

#include "config.h"

#include "data_source_ocv_avcodec.h"

//#include "opencv/highgui.h"
#include "opencv2/highgui/highgui_c.h"

data_source_ocv_avcodec::data_source_ocv_avcodec(const char * name)
{
    int 	numBytes;
    m_name = strdup( name );
    cvNamedWindow( m_name, CV_WINDOW_AUTOSIZE);

    avcodec_register_all();

    // Find the decoder for the video stream
    pCodec=avcodec_find_decoder(AV_CODEC_ID_H264);
    if(pCodec==NULL)
    {
        printf("No codec\n");
    }

    // Open codec
    pCodecCtx = avcodec_alloc_context3( pCodec );
    pCodecCtx->pix_fmt=AV_PIX_FMT_YUV420P;
    pCodecCtx->width=WIDTH;
    pCodecCtx->height=HEIGHT;
    if(avcodec_open2(pCodecCtx, pCodec,NULL)<0)
    {
        printf("couldn't open codec\n");
    }

    // Hack to correct wrong frame rates that seem to be generated by some codecs
    if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
        pCodecCtx->time_base.den=1000;

    // Allocate video frame
    pFrame=av_frame_alloc();

    // Allocate an AVFrame structure
    pFrameRGB=av_frame_alloc();
    if(pFrameRGB==NULL)
    {
        printf("Frame alloc failed\n");
    }

    // Determine required buffer size and allocate buffer
    numBytes=avpicture_get_size(AV_PIX_FMT_RGB24, pCodecCtx->width,pCodecCtx->height);

    buffer=malloc(numBytes);

    // Assign appropriate parts of buffer to image planes in pFrameRGB
    avpicture_fill((AVPicture *)pFrameRGB, (uint8_t*)buffer, AV_PIX_FMT_RGB24,pCodecCtx->width, pCodecCtx->height);
}

data_source_ocv_avcodec::~data_source_ocv_avcodec()
{
    cvDestroyWindow( m_name );
    free( (void*)m_name );

    // Free the RGB image
    free(buffer);
    av_free(pFrameRGB);

    // Close the codec
    // Free the YUV frame
    av_free(pFrame);
    avcodec_close(pCodecCtx);
}

void data_source_ocv_avcodec::write( const uint8_t * data, size_t bytes )
{
    int             frameFinished=0;
    // Decode video frame
    AVPacket avpkt;
    memset( &avpkt, 0x00, sizeof avpkt );
    avpkt.data=(uint8_t*)data;
    avpkt.size=bytes;
    avcodec_decode_video2(pCodecCtx, pFrame,&frameFinished, &avpkt );

    // Did we get a video frame?
    if(frameFinished)
    {
        IplImage * output_image = cvCreateImageHeader(cvSize(pCodecCtx->width,pCodecCtx->height),IPL_DEPTH_8U,3);
        static struct SwsContext *img_convert_ctx;


        // Convert the image into YUV format that SDL uses
        if(img_convert_ctx == NULL)
        {
            int w = pCodecCtx->width;
            int h = pCodecCtx->height;

            img_convert_ctx = sws_getContext(w, h, pCodecCtx->pix_fmt, w, h, AV_PIX_FMT_BGR24, SWS_FAST_BILINEAR ,NULL, NULL, NULL);
            if(img_convert_ctx == NULL)
            {
                fprintf(stderr, "Cannot initialize the conversion context!\n");
                exit(1);
            }
        }
        sws_scale(img_convert_ctx, pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);

        // Blit
        output_image->imageData = (char*)pFrameRGB->data[0];
        cvShowImage(m_name,output_image);
        cvWaitKey(1);
        output_image->imageData = NULL;
        cvReleaseImageHeader( &output_image );
    }
}
